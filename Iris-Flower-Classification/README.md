# 🌸 Iris Flower Classification - Machine Learning Project

The **Iris Flower Classification** project is a classic machine learning task that involves predicting the species of an iris flower based on the length and width of its petals and sepals. This project serves as a foundational exercise in understanding supervised learning, data preprocessing, model training, and evaluation using Python and popular ML libraries.

---

## 📖 Project Overview

This project uses the **Iris dataset**, one of the most well-known and beginner-friendly datasets in the machine learning community. The main objective is to build a classification model that can accurately predict the species of an iris flower among three classes: *Setosa*, *Versicolor*, and *Virginica*.

By applying various machine learning algorithms and evaluating their performance, this project helps in understanding the end-to-end ML pipeline—from data preprocessing to model deployment readiness.

---

## 📊 Dataset Information

- **Features**:
  - Sepal Length
  - Sepal Width
  - Petal Length
  - Petal Width
- **Target**: Iris species (Setosa, Versicolor, Virginica)
- **Total Records**: 150 instances

---

## ⚙️ Technologies & Libraries Used

- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib & Seaborn (for visualization)
- Jupyter Notebook

---

## 🔍 Project Workflow

1. **Data Loading**  
   Load and explore the Iris dataset using pandas.

2. **Exploratory Data Analysis (EDA)**  
   Use Seaborn and Matplotlib to visualize feature relationships and class separability.

3. **Data Preprocessing**  
   - Checking for null values
   - Encoding categorical variables (if needed)
   - Splitting the dataset into train/test sets

4. **Model Training**  
   Trained multiple models including:
   - Logistic Regression
   - K-Nearest
  
5. **Model Evaluation**  
   - Accuracy Score
   - Confusion Matrix
   - Cross-validation

6. **Result Comparison**  
   Compared performance across models to determine the best one based on accuracy and generalization.
   
---

## 📈 Results

- Achieved up to **98–100% accuracy** using models like KNN and Random Forest.
- Visualized classification boundaries and feature importance.
- Demonstrated strong class separability through EDA plots and PCA.
